{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "known-boards",
   "metadata": {},
   "source": [
    "# The add_interface method <3\n",
    "\n",
    "Using data from the Buzsaki data share: https://buzsakilab.nyumc.org/datasets/WatsonBO/BWRat17/BWRat17_121712/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appointed-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from nwb_conversion_tools import NWBConverter, spec\n",
    "from nwb_conversion_tools.interfaces import list_interfaces\n",
    "import pynwb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-school",
   "metadata": {},
   "source": [
    "The base path is the root of a single data directory -- later we will apply it to any number of directories :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "terminal-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('~/Desktop/watson/BWRat17/BWRat17_121712').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "played-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = NWBConverter(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-rough",
   "metadata": {},
   "source": [
    "# Specify Metadata\n",
    "We specify the general structure and location of the data and metadata within a folder, rather than loading it explicitly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-battle",
   "metadata": {},
   "source": [
    "Let's tell it where to find that medaaaadadaaaa. Our session id is the full name of a file named, in this case `'BWRat17_121712.lfp'`, and we want to store this as some metadata nested within `'NWBFile'` -- so let's tell the converter that!\n",
    "\n",
    "We use the `spec.Path` specifier to extract metadata from a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dominican-truck",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NWBFile': {'identifier': 'BWRat17_121712'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid_spec = spec.Path('{NWBFile[identifier]}.lfp')\n",
    "sid_spec.parse(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-gnome",
   "metadata": {},
   "source": [
    "Fabulous! now we can add that to our converter!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "other-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_metadata(sid_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-enhancement",
   "metadata": {},
   "source": [
    "Keep doin that huh? add some more metadata! This dataset uses the date as the `session_start_time` parameter. As a bonus, we can specify multiple pieces of metadata in a single spec -- they get merged at the end don't worry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "neural-austria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NWBFile': {'session_start_time': '121712'},\n",
      " 'Subject': {'subject_id': 'BWRat17'}}\n"
     ]
    }
   ],
   "source": [
    "start_spec = spec.Path('{Subject[subject_id]}_{NWBFile[session_start_time]}.lfp')\n",
    "pprint(start_spec.parse(base_path))\n",
    "converter.add_metadata(start_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-tulsa",
   "metadata": {},
   "source": [
    "Static metadata is also fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sporting-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_metadata({'NWBFile':{'institution':'NYU'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-discussion",
   "metadata": {},
   "source": [
    "# Specifying Interfaces\n",
    "\n",
    "\n",
    "To see the available interfaces, we can just ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "binding-hydrogen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'nwb_conversion_tools.interfaces.imaging.imaging.TiffImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.imaging.imaging.Hdf5ImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.imaging.imaging.SbxImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.blackrock.BlackrockRecordingExtractorInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.ced.CEDRecordingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.intan.IntanRecordingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.neuroscope.NeuroscopeRecordingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.neuroscope.NeuroscopeMultiRecordingTimeInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.open_ephys.OpenEphysRecordingExtractorInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.spike_glx.SpikeGLXRecordingInterface'>]\n"
     ]
    }
   ],
   "source": [
    "# list all interfaces\n",
    "pprint(list_interfaces()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fossil-canadian",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'nwb_conversion_tools.interfaces.imaging.imaging.TiffImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.imaging.imaging.Hdf5ImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.imaging.imaging.SbxImagingInterface'>]\n"
     ]
    }
   ],
   "source": [
    "# list interfaces of a specific category\n",
    "pprint(list_interfaces('imaging'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "passing-history",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nwb_conversion_tools.interfaces.imaging.imaging.TiffImagingInterface"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and get a specific interface\n",
    "tiff_interface = list_interfaces('imaging', 'tiff')\n",
    "tiff_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intimate-carter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imaging\n",
      "tiff\n"
     ]
    }
   ],
   "source": [
    "# the search depends on the class attributes\n",
    "print('\\n'.join((\n",
    "    tiff_interface.interface_type, \n",
    "    tiff_interface.device_name))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-navigation",
   "metadata": {},
   "source": [
    "## Adding a Neuroscope Sorting Interface\n",
    "\n",
    "Using that syntax, we can programmatically add an interface to our dataset spec. First we can query what parameters we need to add it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "simple-animal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Schema for ABCMeta\n",
      "-------------------------\n",
      "{'additionalProperties': False,\n",
      " 'properties': {'exclude_shanks': {'type': 'array'},\n",
      "                'folder_path': {'type': 'string'},\n",
      "                'gain': {'type': 'number'},\n",
      "                'keep_mua_units': {'default': True, 'type': 'boolean'},\n",
      "                'load_waveforms': {'default': False, 'type': 'boolean'}},\n",
      " 'required': ['folder_path'],\n",
      " 'type': 'object'}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "converter.add_interface('sorting', 'neuroscope')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-solomon",
   "metadata": {},
   "source": [
    "We can specify `folder_path`, `gain`, and some others, but `folder_path` is required..\n",
    "\n",
    "Let's use another spec -- this time the `Glob` spec, which is sort of the opposite of the `Path` spec -- using a pattern and/or some metadata, specify a file. in this case the data is originally in the base directory, but that's no fun! let's put them in a subdirectory that uses the subject id just to make it a lil more fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stone-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = base_path / \"BWRat17_121712\"\n",
    "sub_path.mkdir(exist_ok=True)\n",
    "\n",
    "matches = list(base_path.glob('*.clu*'))\n",
    "matches.extend(list(base_path.glob('*.res*')))\n",
    "matches.extend(list(base_path.glob('*.xml')))\n",
    "matches.extend(list(base_path.glob('*.spk*')))\n",
    "\n",
    "for match in matches:\n",
    "    match.rename(sub_path / match.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-proportion",
   "metadata": {},
   "source": [
    "Now we use the `Glob`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "entertaining-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_interface(\n",
    "    'sorting', 'neuroscope', \n",
    "    spec.Glob('folder_path', \n",
    "              '{NWBFile[identifier]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "collectible-drawing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonny/git/nwb-conversion-tools/venv/lib/python3.8/site-packages/pynwb/file.py:753: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  warn(\"Date is missing timezone information. Updating to local timezone.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB file saved at /Users/jonny/test_nwb.nwb!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "root pynwb.file.NWBFile at 0x6152222656\n",
       "Fields:\n",
       "  file_create_date: [datetime.datetime(2021, 4, 1, 14, 5, 11, 137379, tzinfo=tzlocal())]\n",
       "  identifier: a5829ab6-26b2-4881-85e7-def33049bd65\n",
       "  institution: NYU\n",
       "  session_description: no description\n",
       "  session_start_time: 1970-01-01 00:00:00-08:00\n",
       "  subject: subject pynwb.file.Subject at 0x6152221696\n",
       "Fields:\n",
       "  subject_id: BWRat17\n",
       "\n",
       "  timestamps_reference_time: 1970-01-01 00:00:00-08:00\n",
       "  units: units <class 'pynwb.misc.Units'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = Path('~').expanduser() / 'test_nwb.nwb'\n",
    "converter.run_conversion(nwbfile_path=str(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-cosmetic",
   "metadata": {},
   "source": [
    "Did it work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "taken-parade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root pynwb.file.NWBFile at 0x6152224192\n",
      "Fields:\n",
      "  file_create_date: [datetime.datetime(2021, 4, 1, 14, 5, 11, 137379, tzinfo=tzoffset(None, -25200))]\n",
      "  identifier: a5829ab6-26b2-4881-85e7-def33049bd65\n",
      "  institution: NYU\n",
      "  session_description: no description\n",
      "  session_start_time: 1970-01-01 00:00:00-08:00\n",
      "  subject: subject pynwb.file.Subject at 0x6179334080\n",
      "Fields:\n",
      "  subject_id: BWRat17\n",
      "\n",
      "  timestamps_reference_time: 1970-01-01 00:00:00-08:00\n",
      "  units: units <class 'pynwb.misc.Units'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "io = pynwb.NWBHDF5IO(str(output_path), 'r')\n",
    "nwbfile_in = io.read()\n",
    "print(nwbfile_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-batman",
   "metadata": {},
   "source": [
    "Uh oh! looks like the nwb library quietly errored in its attempt to convert our timestamp string `'121712'`! we'll need to add postprocessing/reformatting to `spec` objects (should be np just another argument yno) Other than that we got it tho. It also looks like pynwb overwrites `identifier` with a hash, which I think is as-advertised, but this too passes silently! \n",
    "\n",
    "how about our spikes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "swedish-million",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units pynwb.misc.Units at 0x6152340096\n",
      "Fields:\n",
      "  colnames: ['spike_times']\n",
      "  columns: (\n",
      "    spike_times_index <class 'hdmf.common.table.VectorIndex'>,\n",
      "    spike_times <class 'hdmf.common.table.VectorData'>\n",
      "  )\n",
      "  description: Autogenerated by NWBFile\n",
      "  id: id <class 'hdmf.common.table.ElementIdentifiers'>\n",
      "  waveform_unit: volts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(nwbfile_in.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-universe",
   "metadata": {},
   "source": [
    "Hooray!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-spirit",
   "metadata": {},
   "source": [
    "# Saving/Restoring Conversion Config\n",
    "\n",
    "Assuming we have a quasi-stable structure to at least some of our data, we might want to re-use this configuration. We can save and load our converter configurations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nearby-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converter parameterization saved to converter_config.json\n",
      "{'interfaces': [{'device_name': 'neuroscope',\n",
      "                 'interface_type': 'sorting',\n",
      "                 'kwargs': {},\n",
      "                 'spec': {'children': [],\n",
      "                          'class': 'Glob',\n",
      "                          'kwargs': {'format': '{NWBFile[identifier]}',\n",
      "                                     'key': 'folder_path',\n",
      "                                     'retype': None},\n",
      "                          'module': 'nwb_conversion_tools.spec.path'}}],\n",
      " 'metadata_spec': [{'children': [],\n",
      "                    'class': 'Path',\n",
      "                    'kwargs': {'format': '{NWBFile[identifier]}.lfp',\n",
      "                               'retype': None},\n",
      "                    'module': 'nwb_conversion_tools.spec.path'},\n",
      "                   {'children': [],\n",
      "                    'class': 'Path',\n",
      "                    'kwargs': {'format': '{Subject[subject_id]}_{NWBFile[session_start_time]}.lfp',\n",
      "                               'retype': None},\n",
      "                    'module': 'nwb_conversion_tools.spec.path'}],\n",
      " 'static_metadata': {'NWBFile': {'institution': 'NYU'}}}\n"
     ]
    }
   ],
   "source": [
    "json_path = Path()/'converter_config.json'\n",
    "\n",
    "converter_json = converter.to_json(json_path)\n",
    "\n",
    "pprint(converter_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-inventory",
   "metadata": {},
   "source": [
    "Make a new one using the `from_json` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "jewish-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter_2 = NWBConverter.from_json(json_path)\n",
    "\n",
    "assert converter_json == converter_2.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-merit",
   "metadata": {},
   "source": [
    "# Convert many folders\n",
    "\n",
    "Now that we've got a converter, goode and true, it's easy to apply it to many directories :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acute-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 sec.//.\n",
    "# converter_2.convert_many(base_path.parent.glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-grade",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Now that we've got an abstract representation of a dataset, we should be able to save it, load it, etc.\n",
    "* It is also trivial to then apply it to a list of directories by making a simple `apply`-like method.  \n",
    "* ??? lots more development ???\n",
    "\n",
    "like this is what i'm on about:\n",
    "```\n",
    "converter = NWBConverter.from_spec('spec_file.pck')\n",
    "converter.apply('/data/experiments/*')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-roman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-immunology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwbvenv",
   "language": "python",
   "name": "nwbvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

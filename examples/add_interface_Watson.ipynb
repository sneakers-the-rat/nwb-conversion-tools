{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "known-boards",
   "metadata": {},
   "source": [
    "# The add_interface method <3\n",
    "\n",
    "Using data from the Buzsaki data share: https://buzsakilab.nyumc.org/datasets/WatsonBO/BWRat17/BWRat17_121712/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from nwb_conversion_tools import NWBConverter, spec\n",
    "from nwb_conversion_tools.interfaces import list_interfaces\n",
    "import pynwb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-school",
   "metadata": {},
   "source": [
    "The base path is the root of a single data directory -- later we will apply it to any number of directories :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('~/Desktop/watson/BWRat17/BWRat17_121712').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = NWBConverter(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-rough",
   "metadata": {},
   "source": [
    "# Specify Metadata\n",
    "We specify the general structure and location of the data and metadata within a folder, rather than loading it explicitly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-battle",
   "metadata": {},
   "source": [
    "Let's tell it where to find that medaaaadadaaaa. Our session id is the full name of a file named, in this case `'BWRat17_121712.lfp'`, and we want to store this as some metadata nested within `'NWBFile'` -- so let's tell the converter that!\n",
    "\n",
    "We use the `spec.Path` specifier to extract metadata from a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_spec = spec.Path('{NWBFile[identifier]}.lfp')\n",
    "sid_spec.parse(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-gnome",
   "metadata": {},
   "source": [
    "Fabulous! now we can add that to our converter!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_metadata(sid_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-enhancement",
   "metadata": {},
   "source": [
    "Keep doin that huh? add some more metadata! This dataset uses the date as the `session_start_time` parameter. As a bonus, we can specify multiple pieces of metadata in a single spec -- they get merged at the end don't worry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_spec = spec.Path('{Subject[subject_id]}_{NWBFile[session_start_time]}.lfp')\n",
    "pprint(start_spec.parse(base_path))\n",
    "converter.add_metadata(start_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-tulsa",
   "metadata": {},
   "source": [
    "Static metadata is also fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_metadata({'NWBFile':{'institution':'NYU'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-discussion",
   "metadata": {},
   "source": [
    "# Specifying Interfaces\n",
    "\n",
    "\n",
    "To see the available interfaces, we can just ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-hydrogen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list all interfaces\n",
    "pprint(list_interfaces()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-canadian",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list interfaces of a specific category\n",
    "pprint(list_interfaces('imaging'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and get a specific interface\n",
    "tiff_interface = list_interfaces('imaging', 'tiff')\n",
    "tiff_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the search depends on the class attributes\n",
    "print('\\n'.join((\n",
    "    tiff_interface.interface_type, \n",
    "    tiff_interface.device_name))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-navigation",
   "metadata": {},
   "source": [
    "## Adding a Neuroscope Sorting Interface\n",
    "\n",
    "Using that syntax, we can programmatically add an interface to our dataset spec. First we can query what parameters we need to add it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-animal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converter.add_interface('sorting', 'neuroscope')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-solomon",
   "metadata": {},
   "source": [
    "We can specify `folder_path`, `gain`, and some others, but `folder_path` is required..\n",
    "\n",
    "Let's use another spec -- this time the `Glob` spec, which is sort of the opposite of the `Path` spec -- using a pattern and/or some metadata, specify a file. in this case the data is originally in the base directory, but that's no fun! let's put them in a subdirectory that uses the subject id just to make it a lil more fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = base_path / \"BWRat17_121712\"\n",
    "sub_path.mkdir(exist_ok=True)\n",
    "\n",
    "matches = list(base_path.glob('*.clu*'))\n",
    "matches.extend(list(base_path.glob('*.res*')))\n",
    "matches.extend(list(base_path.glob('*.xml')))\n",
    "matches.extend(list(base_path.glob('*.spk*')))\n",
    "\n",
    "for match in matches:\n",
    "    match.rename(sub_path / match.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-proportion",
   "metadata": {},
   "source": [
    "Now we use the `Glob`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_interface(\n",
    "    'sorting', 'neuroscope', \n",
    "    spec.Glob('folder_path', \n",
    "              '{NWBFile[identifier]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('~').expanduser() / 'test_nwb.nwb'\n",
    "converter.run_conversion(nwbfile_path=str(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-cosmetic",
   "metadata": {},
   "source": [
    "Did it work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "io = pynwb.NWBHDF5IO(str(output_path), 'r')\n",
    "nwbfile_in = io.read()\n",
    "print(nwbfile_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-batman",
   "metadata": {},
   "source": [
    "Uh oh! looks like the nwb library quietly errored in its attempt to convert our timestamp string `'121712'`! we'll need to add postprocessing/reformatting to `spec` objects (should be np just another argument yno) Other than that we got it tho. It also looks like pynwb overwrites `identifier` with a hash, which I think is as-advertised, but this too passes silently! \n",
    "\n",
    "how about our spikes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(nwbfile_in.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-universe",
   "metadata": {},
   "source": [
    "Hooray!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-spirit",
   "metadata": {},
   "source": [
    "# Saving/Restoring Conversion Config\n",
    "\n",
    "Assuming we have a quasi-stable structure to at least some of our data, we might want to re-use this configuration. We can save and load our converter configurations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path()/'converter_config.json'\n",
    "\n",
    "converter_json = converter.to_json(json_path)\n",
    "\n",
    "pprint(converter_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-inventory",
   "metadata": {},
   "source": [
    "Make a new one using the `from_json` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter_2 = NWBConverter.from_json(json_path)\n",
    "\n",
    "assert converter_json == converter_2.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-merit",
   "metadata": {},
   "source": [
    "# Convert many folders\n",
    "\n",
    "Now that we've got a converter, goode and true, it's easy to apply it to many directories :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 sec.//.\n",
    "# converter_2.convert_many(base_path.parent.glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-grade",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Now that we've got an abstract representation of a dataset, we should be able to save it, load it, etc.\n",
    "* It is also trivial to then apply it to a list of directories by making a simple `apply`-like method.  \n",
    "* ??? lots more development ???\n",
    "\n",
    "like this is what i'm on about:\n",
    "```\n",
    "converter = NWBConverter.from_spec('spec_file.pck')\n",
    "converter.apply('/data/experiments/*')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-roman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-immunology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwbvenv",
   "language": "python",
   "name": "nwbvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

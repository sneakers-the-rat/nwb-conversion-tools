{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "honest-ancient",
   "metadata": {},
   "source": [
    "# The add_interface method <3\n",
    "\n",
    "Using data from the Buzsaki data share: https://buzsakilab.nyumc.org/datasets/WatsonBO/BWRat17/BWRat17_121712/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clean-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from nwb_conversion_tools import NWBConverter, spec\n",
    "from nwb_conversion_tools.interfaces import list_interfaces\n",
    "import pynwb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-joyce",
   "metadata": {},
   "source": [
    "The base path is the root of a single data directory -- later we will apply it to any number of directories :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liable-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('~/Desktop/watson/BWRat17/BWRat17_121712').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "historical-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = NWBConverter(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-tours",
   "metadata": {},
   "source": [
    "# Specify Metadata\n",
    "We specify the general structure and location of the data and metadata within a folder, rather than loading it explicitly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-floating",
   "metadata": {},
   "source": [
    "Let's tell it where to find that medaaaadadaaaa. Our session id is the full name of a file named, in this case `'BWRat17_121712.lfp'`, and we want to store this as some metadata nested within `'NWBFile'` -- so let's tell the converter that!\n",
    "\n",
    "We use the `spec.Path` specifier to extract metadata from a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "educated-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NWBFile': {'identifier': 'BWRat17_121712'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid_spec = spec.Path('{NWBFile[identifier]}.lfp')\n",
    "sid_spec.parse(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-medicaid",
   "metadata": {},
   "source": [
    "Fabulous! now we can add that to our converter!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "derived-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_metadata(sid_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-sheet",
   "metadata": {},
   "source": [
    "Keep doin that huh? add some more metadata! This dataset uses the date as the `session_start_time` parameter. As a bonus, we can specify multiple pieces of metadata in a single spec -- they get merged at the end don't worry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hollywood-africa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NWBFile': {'session_start_time': '121712'},\n",
      " 'Subject': {'subject_id': 'BWRat17'}}\n"
     ]
    }
   ],
   "source": [
    "start_spec = spec.Path('{Subject[subject_id]}_{NWBFile[session_start_time]}.lfp')\n",
    "pprint(start_spec.parse(base_path))\n",
    "converter.add_metadata(start_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-chase",
   "metadata": {},
   "source": [
    "Static metadata is also fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifteen-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_metadata({'NWBFile':{'institution':'NYU'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-horizon",
   "metadata": {},
   "source": [
    "# Specifying Interfaces\n",
    "\n",
    "\n",
    "To see the available interfaces, we can just ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "speaking-roulette",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'nwb_conversion_tools.interfaces.imaging.imaging.TiffImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.imaging.imaging.Hdf5ImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.imaging.imaging.SbxImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.blackrock.BlackrockRecordingExtractorInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.ced.CEDRecordingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.intan.IntanRecordingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.neuroscope.NeuroscopeRecordingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.neuroscope.NeuroscopeMultiRecordingTimeInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.open_ephys.OpenEphysRecordingExtractorInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.recording.spike_glx.SpikeGLXRecordingInterface'>]\n"
     ]
    }
   ],
   "source": [
    "# list all interfaces\n",
    "pprint(list_interfaces()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "three-latter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'nwb_conversion_tools.interfaces.imaging.imaging.TiffImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.imaging.imaging.Hdf5ImagingInterface'>,\n",
      " <class 'nwb_conversion_tools.interfaces.imaging.imaging.SbxImagingInterface'>]\n"
     ]
    }
   ],
   "source": [
    "# list interfaces of a specific category\n",
    "pprint(list_interfaces('imaging'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "developing-somewhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nwb_conversion_tools.interfaces.imaging.imaging.TiffImagingInterface"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and get a specific interface\n",
    "tiff_interface = list_interfaces('imaging', 'tiff')\n",
    "tiff_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stupid-hotel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imaging\n",
      "tiff\n"
     ]
    }
   ],
   "source": [
    "# the search depends on the class attributes\n",
    "print('\\n'.join((\n",
    "    tiff_interface.interface_type, \n",
    "    tiff_interface.device_name))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-miracle",
   "metadata": {},
   "source": [
    "## Adding a Neuroscope Sorting Interface\n",
    "\n",
    "Using that syntax, we can programmatically add an interface to our dataset spec. First we can query what parameters we need to add it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "designing-humanity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Schema for ABCMeta\n",
      "-------------------------\n",
      "{'additionalProperties': False,\n",
      " 'properties': {'exclude_shanks': {'type': 'array'},\n",
      "                'folder_path': {'type': 'string'},\n",
      "                'gain': {'type': 'number'},\n",
      "                'keep_mua_units': {'default': True, 'type': 'boolean'},\n",
      "                'load_waveforms': {'default': False, 'type': 'boolean'}},\n",
      " 'required': ['folder_path'],\n",
      " 'type': 'object'}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "converter.add_interface('sorting', 'neuroscope')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-assessment",
   "metadata": {},
   "source": [
    "We can specify `folder_path`, `gain`, and some others, but `folder_path` is required..\n",
    "\n",
    "Let's use another spec -- this time the `Glob` spec, which is sort of the opposite of the `Path` spec -- using a pattern and/or some metadata, specify a file. in this case the data is originally in the base directory, but that's no fun! let's put them in a subdirectory that uses the subject id just to make it a lil more fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "designing-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = base_path / \"BWRat17_121712\"\n",
    "sub_path.mkdir(exist_ok=True)\n",
    "\n",
    "matches = list(base_path.glob('*.clu*'))\n",
    "matches.extend(list(base_path.glob('*.res*')))\n",
    "matches.extend(list(base_path.glob('*.xml')))\n",
    "matches.extend(list(base_path.glob('*.spk*')))\n",
    "\n",
    "for match in matches:\n",
    "    match.rename(sub_path / match.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-proportion",
   "metadata": {},
   "source": [
    "Now we use the `Glob`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "demonstrated-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.add_interface(\n",
    "    'sorting', 'neuroscope', \n",
    "    spec.Glob('folder_path', \n",
    "              '{NWBFile[identifier]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alleged-intention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonny/git/nwb-conversion-tools/venv/lib/python3.8/site-packages/pynwb/file.py:753: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  warn(\"Date is missing timezone information. Updating to local timezone.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB file saved at /Users/jonny/test_nwb.nwb!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "root pynwb.file.NWBFile at 0x6041633504\n",
       "Fields:\n",
       "  file_create_date: [datetime.datetime(2021, 3, 31, 23, 8, 5, 401353, tzinfo=tzlocal())]\n",
       "  identifier: 54a51c63-1eb3-4fd8-ae7e-6a6d29d3b5e7\n",
       "  institution: NYU\n",
       "  session_description: no description\n",
       "  session_start_time: 1970-01-01 00:00:00-08:00\n",
       "  subject: subject pynwb.file.Subject at 0x6041633264\n",
       "Fields:\n",
       "  subject_id: BWRat17\n",
       "\n",
       "  timestamps_reference_time: 1970-01-01 00:00:00-08:00\n",
       "  units: units <class 'pynwb.misc.Units'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = Path('~').expanduser() / 'test_nwb.nwb'\n",
    "converter.run_conversion(nwbfile_path=str(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-gnome",
   "metadata": {},
   "source": [
    "Did it work? Our converter seems to think so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "advised-editing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NWBFile': {'session_description': 'no description',\n",
       "  'session_start_time': datetime.datetime(1970, 1, 1, 0, 0),\n",
       "  'identifier': '0a2fe04b-0b75-40fe-9ff5-d7dc67651e5a'},\n",
       " 'Ecephys': {'Device': [{'description': 'BWRat17_121712.xml'}],\n",
       "  'ElectrodeGroup': [{'name': 'shank1', 'description': 'shank1 electrodes'},\n",
       "   {'name': 'shank2', 'description': 'shank2 electrodes'},\n",
       "   {'name': 'shank3', 'description': 'shank3 electrodes'},\n",
       "   {'name': 'shank4', 'description': 'shank4 electrodes'},\n",
       "   {'name': 'shank5', 'description': 'shank5 electrodes'},\n",
       "   {'name': 'shank6', 'description': 'shank6 electrodes'},\n",
       "   {'name': 'shank7', 'description': 'shank7 electrodes'},\n",
       "   {'name': 'shank8', 'description': 'shank8 electrodes'},\n",
       "   {'name': 'shank9', 'description': 'shank9 electrodes'}],\n",
       "  'Electrodes': [{'name': 'shank_electrode_number',\n",
       "    'description': '0-indexed channel within a shank.',\n",
       "    'data': [0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     0,\n",
       "     1,\n",
       "     2,\n",
       "     3]},\n",
       "   {'name': 'group_name',\n",
       "    'description': 'The name of the ElectrodeGroup this electrode is a part of.',\n",
       "    'data': ['shank1',\n",
       "     'shank1',\n",
       "     'shank1',\n",
       "     'shank1',\n",
       "     'shank1',\n",
       "     'shank1',\n",
       "     'shank1',\n",
       "     'shank1',\n",
       "     'shank2',\n",
       "     'shank2',\n",
       "     'shank2',\n",
       "     'shank2',\n",
       "     'shank2',\n",
       "     'shank2',\n",
       "     'shank2',\n",
       "     'shank2',\n",
       "     'shank3',\n",
       "     'shank3',\n",
       "     'shank3',\n",
       "     'shank3',\n",
       "     'shank3',\n",
       "     'shank3',\n",
       "     'shank3',\n",
       "     'shank3',\n",
       "     'shank4',\n",
       "     'shank4',\n",
       "     'shank4',\n",
       "     'shank4',\n",
       "     'shank4',\n",
       "     'shank4',\n",
       "     'shank4',\n",
       "     'shank4',\n",
       "     'shank5',\n",
       "     'shank5',\n",
       "     'shank5',\n",
       "     'shank5',\n",
       "     'shank5',\n",
       "     'shank5',\n",
       "     'shank5',\n",
       "     'shank6',\n",
       "     'shank6',\n",
       "     'shank6',\n",
       "     'shank6',\n",
       "     'shank6',\n",
       "     'shank6',\n",
       "     'shank6',\n",
       "     'shank7',\n",
       "     'shank7',\n",
       "     'shank7',\n",
       "     'shank7',\n",
       "     'shank7',\n",
       "     'shank7',\n",
       "     'shank7',\n",
       "     'shank7',\n",
       "     'shank8',\n",
       "     'shank8',\n",
       "     'shank8',\n",
       "     'shank8',\n",
       "     'shank8',\n",
       "     'shank8',\n",
       "     'shank8',\n",
       "     'shank8',\n",
       "     'shank9',\n",
       "     'shank9',\n",
       "     'shank9',\n",
       "     'shank9']}]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.get_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-miniature",
   "metadata": {},
   "source": [
    "Woohoo! we got 'em!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "registered-investor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units pynwb.misc.Units at 0x6069716880\n",
      "Fields:\n",
      "  colnames: ['spike_times']\n",
      "  columns: (\n",
      "    spike_times_index <class 'hdmf.common.table.VectorIndex'>,\n",
      "    spike_times <class 'hdmf.common.table.VectorData'>\n",
      "  )\n",
      "  description: Autogenerated by NWBFile\n",
      "  id: id <class 'hdmf.common.table.ElementIdentifiers'>\n",
      "  waveform_unit: volts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "io = pynwb.NWBHDF5IO(str(output_path), 'r')\n",
    "nwbfile_in = io.read()\n",
    "print(nwbfile_in.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-peripheral",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Now that we've got an abstract representation of a dataset, we should be able to save it, load it, etc.\n",
    "* It is also trivial to then apply it to a list of directories by making a simple `apply`-like method.  \n",
    "* ??? lots more development ???\n",
    "\n",
    "like this is what i'm on about:\n",
    "```\n",
    "converter = NWBConverter.from_spec('spec_file.pck')\n",
    "converter.apply('/data/experiments/*')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-willow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-traveler",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwbvenv",
   "language": "python",
   "name": "nwbvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
